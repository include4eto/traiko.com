<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="ie=edge">
        <title>Traiko Dinev - Personal Webpage</title>
    
        <link rel="stylesheet" href="/styles/font-awesome-4.7.0/css/font-awesome.min.css">
        <link href="/styles/ptsans.css" rel="stylesheet">
        <link href="/styles/main.css" rel="stylesheet">
        <link href="/styles/common.css" rel="stylesheet">
        <link href="/styles/innerpage.css" rel="stylesheet">
    </head>
    
    <body class="innerpage dire">
        <header>
            <div class="row">
                <div class="title">
                    <div class="name">
                        <h1>Traiko Dinev</h1>
                        <div class="assoc">University of Edinburgh CS Student</div>
                        <div class="email">traiko.dinev at gmail.com</div>
                    </div>
                </div>
            </div>
        </header>
        
        <section class="links">
            <div class="wrapper">
                <p>
                    <a href="/">Don't want to be here? Go back</a>
                </p>

                <h1>Dynamic Likelihood-free Inference via Ratio Estimation (DIRE)</h1>
                <em>This page is currently a draft. See the arxiv paper <a href="">here</a>.</em>
                <p>
                    Let's say we have constructed some model of a natural process. For instance,
                    let's say we are looking at stock market prices. It might very well be that
                    all that movement is described by a few variables. For instance, it might be
                    that Sony's share price is mostly affected by how many people buy
                    their headphones and at what price. If we were hardened Wall Street brokers, we might
                    have come up with a model of how exactly the share price is affected by these variables. This model of ours would take in the number of customers and average price and
                    produce a timeline of stock prices.
                    
                    Once we are convinced our model is correct, we  could start applying it to the actual stock market.
                    Looking at Sony's share prices (the observed data) we could ask the inverse question, so to speak - how many
                    customers does Sony have? 
                </p>
                <p>
                    This is a harder problem to solve. We do have a <em>model</em> that takes in the number
                    of people buying Sony Headphones and produces a list of prices of shares over time. Going backwards
                    is not necessarily as easy. Given the lots of random variations in the data, it is
                    likely that many different outputs (share prices) could be generated by the same inputs (number of Sony customers and average price). In other words, our model has some sort of randomness built-in. This
                    is inherent in the process anyway - as any investor will tell you, share prices fluctuate all the time
                    even without any apparent change in the company,  
                </p>


                <div class="center img">
                    <img class="model-diagram" src="figures/model_diagram.svg">
                </div>

                <h2>Background: Approximate Bayesian Computation</h2>
                <p class="intro">
                    The above, in a nutshell, is what we are trying to solve. Normally we create something called the
                    likelihood, i.e. the probability of the data, given the model. This represents the probability that
                    the outputs (the real stock prices) are generated by the inputs (the number of customers and average price).
                </p>

    
                $$
                    P(\mathcal{D}\ |\ \mathcal{M}) = P(\text{outputs}\ |\ \text{inputs})
                $$

                <p>
                    Here $\mathcal{D}$ represents data and $\mathcal{M}$ - our <em>model</em> of the market. Remember, our
                    model has some randomness, so a lot of different <em>outputs</em> are possible for the same <em>input</em>
                    if we run the model multiple times. If we could maximize the above with respect to our <em>inputs</em>, we
                    more or less done. We can answer with confidence which input parameters are <em>most likely</em> to produce
                    the output. Approximate Bayesian Computation comes in when the above is <strong>very hard to compute</strong>.
                </p>

                <p>
                    Let's introduce some common notation. We will call our model inputs $\bf{\theta}$ and our model outputs $\bf{x}$. Letters in bold will repesent vectors. So for instance the number of people who buy Sony headphones and the price of headphones
                    would both be captured in theta: $\bf{\theta} = \{\theta_1, \theta_2\}$. The share prices we are currently
                    looking and are analyzing are the <em>observed data</em>, denoted by $\bf{x}^{(\text{obs})}$. We would like
                    to know what $\bf{\theta}$ could generate $\bf{x}^{(\text{obs})}$ with what probability.
                </p>
                    
                <p>
                    Our inputs values are not exactly
                    random - We know some relative bound for the number of Sony customers, for instance. We can thus put a 
                    <strong>prior</strong> on $\bf{\theta}$. If we think that between 10 and 1,000,000 people buy Sony headphones (a very <em>broad</em> prior), we can encode that information. We have defined what is called
                    a uniform prior - we think it is equally likely that Sony has any number of customers between 10 and 1,000,000. This is (obviously) a very wrong assumption. We specify it mathematically:
                </p>

                $$
                    \pi(\theta_1) = P(\theta_1) = \mathcal{U}(10;\ 1,000,000)
                $$

                <p>
                    We can now <strong>draw samples</strong> from our prior. That is, we can generate random values
                    for $\bf{\theta}$ by randomly selecting a value within that range we just set up. Mathematically we
                    wish to compute what is known as the <em>posterior</em> or $P(\theta\ |\ \bf{x}^{(obs)})$. Computing this
                    quantity for various parameter values $\theta$ will give us the distribution of $\theta$ values and for 
                    each how likely it is to generate $\bf{x}^{(obs)}$ using it. This probability is impossible to compute,
                    as we noted earlier. If we could com can
                    be inverted by using Bayes' theorem like so:
                </p>

                $$
                    P(\theta\ |\ \bf{x}) = \frac{
                        \text{P}(\bf{x} |\ \theta) \text{P}(\theta)
                    }{
                        \text{P}(\bf{x})
                    }
                $$

                Notice that $P(\theta)$ is our prior, which can also be written as $\pi(\theta)$. 

                <div class="center img">
                    <img class="rej-sampling" src="figures/rej_sampling_diagram.svg">
                </div>
                
                <section class="arch">
                    <div class="controls">
                        <div class="slidecontainer">
                            <div class="title">$\theta_1$</div>
                            
                            <div class="slider" data-bind="slider: theta1">
                                <div class="slider-inner"></div>
                            </div>
                        </div>
                        <div class="slidecontainer">
                            <div class="title">$\theta_2$</div>
                            
                            <div class="slider" data-bind="slider: theta2">
                                <div class="slider-inner"></div>
                            </div>
                        </div>
                    </div>

                    <div class="arch-data">
                        <canvas id="arch-data"  height="400px"></canvas> 
                    </div>
                    
                    <div class="lfire">
                        <canvas id="lfire-theta1"  height="400px"></canvas>
                        <canvas id="lfire-theta2"  height="400px"></canvas>
                    </div>
                </section>
            </div>
        </section>

        <script src='/scripts/lib/knockout-3.4.2.js'></script>

        <script src="/scripts/lib/tfjs.js"> </script>
        
        <script src='/scripts/lib/jquery-3.3.1.min.js'></script>
        <script src='/scripts/lib/Chart.bundle.min.js'></script>
        <script src='/scripts/lib/numjs.min.js'></script>
        <script src='/scripts/lib/mathjax/MathJax.js'></script>

        <script src='/scripts/aux.js'></script>
        <script src='/scripts/pages/dire.js'></script>
    </body>
    </html>